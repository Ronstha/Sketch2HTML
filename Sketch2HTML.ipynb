{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55e0a9cb",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-03-09T17:45:35.010519Z",
          "iopub.status.busy": "2025-03-09T17:45:35.010266Z",
          "iopub.status.idle": "2025-03-09T17:45:48.342097Z",
          "shell.execute_reply": "2025-03-09T17:45:48.341405Z"
        },
        "papermill": {
          "duration": 13.345172,
          "end_time": "2025-03-09T17:45:48.344019",
          "exception": false,
          "start_time": "2025-03-09T17:45:34.998847",
          "status": "completed"
        },
        "tags": [],
        "id": "55e0a9cb"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import shutil\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "import time\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "de8RGWvacSor"
      },
      "id": "de8RGWvacSor"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df2fcf89",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:45:48.390974Z",
          "iopub.status.busy": "2025-03-09T17:45:48.389901Z",
          "iopub.status.idle": "2025-03-09T17:45:48.395757Z",
          "shell.execute_reply": "2025-03-09T17:45:48.394973Z"
        },
        "papermill": {
          "duration": 0.022399,
          "end_time": "2025-03-09T17:45:48.397604",
          "exception": false,
          "start_time": "2025-03-09T17:45:48.375205",
          "status": "completed"
        },
        "tags": [],
        "id": "df2fcf89"
      },
      "outputs": [],
      "source": [
        "tokens=[\n",
        "    '<PAD>',\n",
        "    '{',\n",
        "    '}',\n",
        "    'row',\n",
        "    'header',\n",
        "    'footer',\n",
        "    'container',\n",
        "    'text',\n",
        "    'text-r',\n",
        "    'text-c',\n",
        "    'flex-sb',\n",
        "    'flex',\n",
        "    'flex-c',\n",
        "    'flex-r',\n",
        "    'image',\n",
        "    'carousel',\n",
        "    'paragraph',\n",
        "    'div-3',\n",
        "    'div-6',\n",
        "    'div-12',\n",
        "    'div-9',\n",
        "    'input',\n",
        "    'nav',\n",
        "    'logodiv',\n",
        "    'navlink',\n",
        "    'table',\n",
        "    'button',\n",
        "    'button-c',\n",
        "    'button-r',\n",
        "    'card',\n",
        "    '<END>',\n",
        "    '<START>'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a802b69",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:45:48.419129Z",
          "iopub.status.busy": "2025-03-09T17:45:48.418853Z",
          "iopub.status.idle": "2025-03-09T17:45:48.422824Z",
          "shell.execute_reply": "2025-03-09T17:45:48.422044Z"
        },
        "papermill": {
          "duration": 0.016887,
          "end_time": "2025-03-09T17:45:48.424408",
          "exception": false,
          "start_time": "2025-03-09T17:45:48.407521",
          "status": "completed"
        },
        "tags": [],
        "id": "0a802b69"
      },
      "outputs": [],
      "source": [
        "t2v={}\n",
        "v2t={}\n",
        "for i in range(len(tokens)):\n",
        "    v2t[i]=tokens[i]\n",
        "    t2v[tokens[i]]=i\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05e85641",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:45:48.445689Z",
          "iopub.status.busy": "2025-03-09T17:45:48.445230Z",
          "iopub.status.idle": "2025-03-09T17:45:48.451394Z",
          "shell.execute_reply": "2025-03-09T17:45:48.450604Z"
        },
        "papermill": {
          "duration": 0.018594,
          "end_time": "2025-03-09T17:45:48.452921",
          "exception": false,
          "start_time": "2025-03-09T17:45:48.434327",
          "status": "completed"
        },
        "tags": [],
        "id": "05e85641"
      },
      "outputs": [],
      "source": [
        "#functions to convert token to text\n",
        "def dsltotoken(dsl):\n",
        "    tks=['<START>']\n",
        "    for tk in [i.strip() for i in dsl.strip().split('\\n')]:\n",
        "      if tk==\"\": continue\n",
        "      if(tk.endswith(\"{\")):\n",
        "        tks.append(tk[:-1])\n",
        "        tks.append(tk[-1])\n",
        "      else:\n",
        "        tks.append(tk)\n",
        "    tks.append('<END>')\n",
        "    return [t2v[tokens] for tokens in tks]\n",
        "\n",
        "def tokentodsl(tokens):\n",
        "    tokens=[v2t[vec] for vec in tokens]\n",
        "    tokens.pop(0)\n",
        "    tokens.pop()\n",
        "    txt=\"\"\n",
        "    stack=[]\n",
        "\n",
        "    for i in tokens:\n",
        "      if(i==\"{\"):\n",
        "        txt+=\"{\"\n",
        "        stack.append(\"{\")\n",
        "        continue\n",
        "      elif(i==\"}\"):\n",
        "        stack.pop()\n",
        "\n",
        "      txt+='\\n'+'\\t'*len(stack)+i\n",
        "    txt=txt.strip()\n",
        "    return txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e464b2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:45:48.473511Z",
          "iopub.status.busy": "2025-03-09T17:45:48.473278Z",
          "iopub.status.idle": "2025-03-09T17:46:09.915116Z",
          "shell.execute_reply": "2025-03-09T17:46:09.914039Z"
        },
        "papermill": {
          "duration": 21.454293,
          "end_time": "2025-03-09T17:46:09.917022",
          "exception": false,
          "start_time": "2025-03-09T17:45:48.462729",
          "status": "completed"
        },
        "tags": [],
        "id": "b0e464b2"
      },
      "outputs": [],
      "source": [
        "#Load Dataset\n",
        "class Data:\n",
        "    def __init__(self,image,dsl):\n",
        "        self.image=image\n",
        "        self.dsl=dsl\n",
        "\n",
        "\n",
        "data=[]\n",
        "folder=\"/kaggle/input/sketch2htmldata\"\n",
        "for fol in os.listdir(\"folder\"):\n",
        "    if fol.lower()=='dsl':\n",
        "        dsl=folder+\"/\"+fol\n",
        "    if fol.lower()=='sketch':\n",
        "        sketch=folder+\"/\"+fol\n",
        "    for sk in os.listdir(sketch):\n",
        "        im=Data(sketch+\"/\"+sk,dsl+\"/\"+sk.split('.')[0]+'.dsl')\n",
        "        data.append(im)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17021d8b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:09.939868Z",
          "iopub.status.busy": "2025-03-09T17:46:09.939384Z",
          "iopub.status.idle": "2025-03-09T17:46:09.945978Z",
          "shell.execute_reply": "2025-03-09T17:46:09.945265Z"
        },
        "papermill": {
          "duration": 0.019592,
          "end_time": "2025-03-09T17:46:09.947554",
          "exception": false,
          "start_time": "2025-03-09T17:46:09.927962",
          "status": "completed"
        },
        "tags": [],
        "id": "17021d8b"
      },
      "outputs": [],
      "source": [
        "#splitting data for training and testing\n",
        "np.random.seed(10)\n",
        "np.random.shuffle(data)\n",
        "n=int(0.7*len(data))\n",
        "train_data=data[0:n]\n",
        "test_data=data[n:]\n",
        "np.random.seed(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5123011",
      "metadata": {
        "papermill": {
          "duration": 0.010314,
          "end_time": "2025-03-09T17:46:10.010603",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.000289",
          "status": "completed"
        },
        "tags": [],
        "id": "a5123011"
      },
      "source": [
        "**ConvolutionalTokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86bb8fad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.032285Z",
          "iopub.status.busy": "2025-03-09T17:46:10.031964Z",
          "iopub.status.idle": "2025-03-09T17:46:10.042664Z",
          "shell.execute_reply": "2025-03-09T17:46:10.042022Z"
        },
        "papermill": {
          "duration": 0.023526,
          "end_time": "2025-03-09T17:46:10.044359",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.020833",
          "status": "completed"
        },
        "tags": [],
        "id": "86bb8fad"
      },
      "outputs": [],
      "source": [
        "class ConvolutionalTokenizer(layers.Layer):\n",
        "    \"\"\"\n",
        "    Creates Convolutional Tokens of images for feeding to Transformer Encoder.\n",
        "    \"\"\"\n",
        "    def __init__(self,kernel_size=3,stride=1,padding=1,pooling_kernel_size=3,pooling_stride=2,conv_layers=2,num_output_channels=[32, 64],**kwargs,):\n",
        "        super(ConvolutionalTokenizer, self).__init__(**kwargs)\n",
        "\n",
        "        # Creating a Sequential Keras Model for Tokenizing images\n",
        "        self.conv_model = keras.Sequential()\n",
        "        self.conv_model.add(layers.Conv2D(32,7,1,padding=\"valid\",use_bias=False,activation=\"relu\"))\n",
        "        self.conv_model.add(layers.ZeroPadding2D(1))\n",
        "        self.conv_model.add(layers.MaxPool2D(3, 2, \"same\"))\n",
        "        self.conv_model.add(layers.Conv2D(64,5,1,padding=\"valid\",use_bias=False,activation=\"relu\"))\n",
        "        self.conv_model.add(layers.ZeroPadding2D(1))\n",
        "        self.conv_model.add(layers.MaxPool2D(3, 2, \"same\"))\n",
        "        self.conv_model.add(layers.Dropout(0.1))\n",
        "        self.conv_model.add(layers.Conv2D(64,3,1,padding=\"valid\",use_bias=False,activation=\"relu\"))\n",
        "        self.conv_model.add(layers.ZeroPadding2D(1))\n",
        "        self.conv_model.add(layers.MaxPool2D(3, 2, \"same\"))\n",
        "        self.conv_model.add(layers.Conv2D(128,3,1,padding=\"valid\",use_bias=False,activation=\"relu\"))\n",
        "        self.conv_model.add(layers.ZeroPadding2D(1))\n",
        "        self.conv_model.add(layers.MaxPool2D(3, 2, \"same\"))\n",
        "        self.conv_model.add(layers.Dropout(0.1))\n",
        "        self.conv_model.add(layers.Conv2D(128,3,1,padding=\"valid\",use_bias=False,activation=\"relu\"))\n",
        "        self.conv_model.add(layers.ZeroPadding2D(1))\n",
        "        self.conv_model.add(layers.MaxPool2D(3, 2, \"same\"))\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, images):\n",
        "        # Reshaping the outputs by flattening them\n",
        "        outputs = self.conv_model(images)\n",
        "        Flattened = tf.reshape(\n",
        "            outputs,\n",
        "            (-1, tf.shape(outputs)[1] * tf.shape(outputs)[2], tf.shape(outputs)[3]),\n",
        "        )\n",
        "        return Flattened\n",
        "\n",
        "    # Adding Learnable Positional Embeddings\n",
        "    def pos_embeddings(self, image_size):\n",
        "        inp = tf.ones((1, image_size[0], image_size[1],1))\n",
        "        out = self.call(inp)\n",
        "        seq_len = tf.shape(out)[1]\n",
        "        projection_dim = tf.shape(out)[-1]\n",
        "        embed_layer = layers.Embedding(\n",
        "            input_dim=seq_len, output_dim=projection_dim\n",
        "        )\n",
        "        return embed_layer, seq_len\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f753e0",
      "metadata": {
        "papermill": {
          "duration": 0.010182,
          "end_time": "2025-03-09T17:46:10.064595",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.054413",
          "status": "completed"
        },
        "tags": [],
        "id": "60f753e0"
      },
      "source": [
        "**Feed Forward Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3783e2d0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.085559Z",
          "iopub.status.busy": "2025-03-09T17:46:10.085346Z",
          "iopub.status.idle": "2025-03-09T17:46:10.089602Z",
          "shell.execute_reply": "2025-03-09T17:46:10.088775Z"
        },
        "papermill": {
          "duration": 0.016664,
          "end_time": "2025-03-09T17:46:10.091143",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.074479",
          "status": "completed"
        },
        "tags": [],
        "id": "3783e2d0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def mlp(x, hidden_units, dropout):\n",
        "    \"\"\"\n",
        "    Creates A Feed Forward Network`\n",
        "\n",
        "    Args:\n",
        "        hidden_units: Number of hidden units in MLP\n",
        "        dropout: The Rate of dropout which is to be applied.\n",
        "    \"\"\"\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b748941",
      "metadata": {
        "papermill": {
          "duration": 0.009891,
          "end_time": "2025-03-09T17:46:10.111500",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.101609",
          "status": "completed"
        },
        "tags": [],
        "id": "9b748941"
      },
      "source": [
        "**Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f9b8ab4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.132374Z",
          "iopub.status.busy": "2025-03-09T17:46:10.132109Z",
          "iopub.status.idle": "2025-03-09T17:46:10.137622Z",
          "shell.execute_reply": "2025-03-09T17:46:10.136653Z"
        },
        "papermill": {
          "duration": 0.01792,
          "end_time": "2025-03-09T17:46:10.139396",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.121476",
          "status": "completed"
        },
        "tags": [],
        "id": "5f9b8ab4"
      },
      "outputs": [],
      "source": [
        "def Transformer_Encoder(L,embedded_patches,num_heads,projection_dim,transformer_units):\n",
        "    \"\"\"\n",
        "    Transformer Encoder Block\n",
        "\n",
        "    Args:\n",
        "        L: number of transformer_layers\n",
        "\n",
        "        embedded_patches: Patches from the Convolutional Tokenizer block\n",
        "\n",
        "        num_heads: Number of Attention Heads\n",
        "\n",
        "        projection_dim: Size of each attention head for query and key\n",
        "\n",
        "        transformer_units: hidden units of MLP\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Iterating over the number of transformer layers\n",
        "    for i in range(L):\n",
        "        # Normalizing the input patches\n",
        "        norm = layers.LayerNormalization(epsilon=1e-5)(embedded_patches)\n",
        "        # Feeding to MHA\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=0.1)(norm,norm)\n",
        "        # Shortcut skip connection\n",
        "        skip1 = layers.Add()([attention_output, embedded_patches])\n",
        "        # Normalizing\n",
        "        norm2= layers.LayerNormalization(epsilon=1e-5)(skip1)\n",
        "\n",
        "        # Feed Forward MLP\n",
        "        ffn = mlp(norm2, hidden_units=transformer_units, dropout=0.1)\n",
        "\n",
        "        # Shortcut skip connection\n",
        "        embedded_patches = layers.Add()([ffn, skip1])\n",
        "\n",
        "    return embedded_patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43635177",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.220777Z",
          "iopub.status.busy": "2025-03-09T17:46:10.220556Z",
          "iopub.status.idle": "2025-03-09T17:46:10.237665Z",
          "shell.execute_reply": "2025-03-09T17:46:10.236711Z"
        },
        "papermill": {
          "duration": 0.030077,
          "end_time": "2025-03-09T17:46:10.239456",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.209379",
          "status": "completed"
        },
        "tags": [],
        "id": "43635177"
      },
      "outputs": [],
      "source": [
        "def create_causal_mask(seq_length):\n",
        "    \"\"\"\n",
        "    Creates a causal (look-ahead) mask for sequence length `seq_length`.\n",
        "    This mask ensures that each position can only attend to previous positions and itself.\n",
        "\n",
        "    Args:\n",
        "        seq_length: The length of the sequence.\n",
        "\n",
        "    Returns:\n",
        "        A tensor of shape (1, 1, seq_length, seq_length) with the causal mask.\n",
        "    \"\"\"\n",
        "    # Create a boolean mask\n",
        "    mask = tf.linalg.band_part(tf.ones((seq_length, seq_length)), -1, 0)\n",
        "\n",
        "    # Convert boolean mask to 0 and -inf (for masking)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    mask = tf.expand_dims(mask, 0)  # Add batch dimension\n",
        "    mask = tf.expand_dims(mask, 0)  # Add head dimension\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "    depth = depth/2\n",
        "    positions = tf.range(length, dtype=tf.float32)[:, tf.newaxis]     # (seq, 1)\n",
        "    depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :]/depth   # (1, depth)\n",
        "    angle_rates = 1 / (10000**depths)               # (1, depth)\n",
        "    angle_rads = positions * angle_rates            # (seq, depth)\n",
        "    pos_encoding = tf.concat([tf.sin(angle_rads), tf.cos(angle_rads)], axis=-1)\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "XOEtz_KnczNx"
      },
      "id": "XOEtz_KnczNx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, patch_size, projection_dim):\n",
        "        super(PatchEmbedding, self).__init__()\n",
        "        self.projection_dim = projection_dim\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.projection = layers.Dense(projection_dim)\n",
        "        self.flatten = layers.Reshape((-1, projection_dim))\n",
        "\n",
        "    def call(self, images):\n",
        "        # Split image into patches\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        # Reshape patches and project them\n",
        "        patches_shape = tf.shape(patches)\n",
        "        patches = tf.reshape(patches, (patches_shape[0], -1, patches_shape[-1]))\n",
        "        return self.projection(patches)"
      ],
      "metadata": {
        "id": "ZEE2k6vEcz14"
      },
      "id": "ZEE2k6vEcz14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Model(model=0,image_size=32,num_classes=29,input_shape=(32, 32, 3),projection_dim=128,num_heads=2,L=2,transformer_units=[128,128],vocab_size=29,max_seq_length=100):\n",
        "\n",
        "    encoder_inputs = layers.Input(input_shape)\n",
        "    if model==1:\n",
        "        \"\"\"\n",
        "        VIT + decoder\n",
        "        \"\"\"\n",
        "        patch_embedding = PatchEmbedding(patch_size=16, projection_dim=projection_dim)\n",
        "        embedded_patches = patch_embedding(encoder_inputs)\n",
        "        pos_encoding = positional_encoding(53*38, projection_dim)\n",
        "        embedded_patches += pos_encoding\n",
        "\n",
        "    else:\n",
        "        \"\"\"\n",
        "        CCT or Convolution + decoder\n",
        "        \"\"\"\n",
        "        conv_tokenizer = ConvolutionalTokenizer()\n",
        "        embedded_patches = conv_tokenizer(encoder_inputs)\n",
        "        pos_embed, seq_length = conv_tokenizer.pos_embeddings(image_size)\n",
        "        positions = tf.range(start=0, limit=seq_length, delta=1)\n",
        "        position_embeddings = pos_embed(positions)\n",
        "        embedded_patches+=position_embeddings\n",
        "\n",
        "    if model==2:#for convolution only\n",
        "        encoder_output=embedded_patches\n",
        "    else:\n",
        "        encoder_output=Transformer_Encoder(L,embedded_patches,num_heads=num_heads,projection_dim=projection_dim,transformer_units=transformer_units)\n",
        "\n",
        "    #decoder input\n",
        "    decoder_inputs = layers.Input(shape=(max_seq_length,))\n",
        "    decoder_embedding = layers.Embedding(vocab_size, projection_dim)(decoder_inputs)\n",
        "    pos_encoding2 = positional_encoding(max_seq_length, projection_dim)\n",
        "    decoder_embedding += pos_encoding2\n",
        "    causal_mask = create_causal_mask(tf.shape(decoder_inputs)[1]) #casual masking\n",
        "    x=decoder_embedding\n",
        "\n",
        "\n",
        "    #decoder layers\n",
        "    for _ in range(L):\n",
        "            x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "            attn_output1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim)(x1, x1,attention_mask=causal_mask)\n",
        "            x = layers.Add()([x, attn_output1])\n",
        "\n",
        "            x2 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "            attn_output2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim)(x2, encoder_output)\n",
        "            x = layers.Add()([x, attn_output2])\n",
        "\n",
        "            x3 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "            ffn = mlp(x3, hidden_units=transformer_units, dropout=0.1)\n",
        "            x = layers.Add()([x, ffn])\n",
        "\n",
        "    decoder_outputs = layers.Dense(vocab_size-1)(x)\n",
        "\n",
        "    model = keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "9NhfwqyBc6gw"
      },
      "id": "9NhfwqyBc6gw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3967e06e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.261185Z",
          "iopub.status.busy": "2025-03-09T17:46:10.260900Z",
          "iopub.status.idle": "2025-03-09T17:46:10.272495Z",
          "shell.execute_reply": "2025-03-09T17:46:10.271766Z"
        },
        "papermill": {
          "duration": 0.024744,
          "end_time": "2025-03-09T17:46:10.274155",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.249411",
          "status": "completed"
        },
        "tags": [],
        "id": "3967e06e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_rect(image):\n",
        "        coords=cv2.findNonZero(image)\n",
        "        x, y, w, h = cv2.boundingRect(coords)\n",
        "        return x,y,w,h\n",
        "#Data Augmentation\n",
        "def get_augment(image):\n",
        "    choice=np.random.random()\n",
        "    if(choice<0.1):\n",
        "        return image\n",
        "    _,thresh=cv2.threshold(image,5,255,cv2.THRESH_BINARY)\n",
        "    x,y,w,h=get_rect(thresh)\n",
        "    sc=False\n",
        "\n",
        "    if((int(choice*100))%2==0 and (sc==True or w<input_shape[1]-80)):\n",
        "        angle=np.random.uniform(low=-3,high=3)\n",
        "        (h, w) = image.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1)\n",
        "        image = cv2.warpAffine(image, M, (w, h))\n",
        "        _,thresh=cv2.threshold(image,5,255,cv2.THRESH_BINARY)\n",
        "        x,y,w,h=get_rect(thresh)\n",
        "    try:\n",
        "       if(choice>0.5):\n",
        "        #translate\n",
        "        newimage=np.zeros_like(image)\n",
        "        transx=x\n",
        "        transy=y\n",
        "        if h<input_shape[0]-200:\n",
        "            transy+=np.random.randint(0,np.max(input_shape[0]-(y+h)-150,1))\n",
        "        if w<input_shape[1]-100:\n",
        "#\n",
        "            transx+=np.random.randint(-x+20,np.max(input_shape[1]-(x+w)-20,1))\n",
        "        newimage[transy:transy+h,transx:transx+w]=image[y:y+h,x:x+w]\n",
        "        image=newimage.copy()\n",
        "    except:\n",
        "        pass\n",
        "    return image\n",
        "\n",
        "def load_image(img,augment=False):\n",
        "    with tf.device(tf.test.gpu_device_name()):\n",
        "        im=cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
        "        resized=cv2.resize(im,(input_shape[1],input_shape[0]),interpolation=cv2.INTER_AREA)\n",
        "        thresh=resized\n",
        "\n",
        "        thresh = thresh.astype(np.float32)\n",
        "        thresh /= 255\n",
        "        thresh = np.expand_dims(thresh, axis=-1)\n",
        "        return thresh\n",
        "def get_tokens(name):\n",
        "    labs=[]\n",
        "    toks=[]\n",
        "    f=open(name,'r')\n",
        "    tkns=dsltotoken(f.read())\n",
        "    return tkns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504fe8f3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.335172Z",
          "iopub.status.busy": "2025-03-09T17:46:10.334841Z",
          "iopub.status.idle": "2025-03-09T17:46:10.343210Z",
          "shell.execute_reply": "2025-03-09T17:46:10.342461Z"
        },
        "papermill": {
          "duration": 0.060543,
          "end_time": "2025-03-09T17:46:10.344670",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.284127",
          "status": "completed"
        },
        "tags": [],
        "id": "504fe8f3"
      },
      "outputs": [],
      "source": [
        "#Dataset Generator\n",
        "class TrainDataGenerator(Sequence):\n",
        "    def __init__(self, data,batch_size):\n",
        "        self.datas =[]\n",
        "        self.batch_size=batch_size\n",
        "        for obj in data:\n",
        "            tkns=get_tokens(obj.dsl)\n",
        "            for i in range(len(tkns)-1,len(tkns)):\n",
        "\n",
        "                t=tkns[:i+1]\n",
        "                t1=tkns[:-1]\n",
        "                t3=tkns[1:]\n",
        "                t1+=[0 for _ in range(MAX_SEQ_LEN-len(t1))]\n",
        "                t2=[0 for _ in range(MAX_SEQ_LEN)]\n",
        "                t2[len(t)-2]=t[-1]\n",
        "\n",
        "                t1+=[0 for _ in range(MAX_SEQ_LEN-len(t1))]\n",
        "                t3+=[0 for _ in range(MAX_SEQ_LEN-len(t3))]\n",
        "                for _ in range(1):\n",
        "                    self.datas.append([obj.image,t1,t3])\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indices = range(index * self.batch_size, (index + 1) * self.batch_size)\n",
        "        image_data=[]\n",
        "        token_data=[]\n",
        "        label=[]\n",
        "        for i in indices:\n",
        "            data=self.datas[i]\n",
        "            image_data.append(load_image(data[0],augment=True))\n",
        "\n",
        "            token_data.append(np.array(data[1]))\n",
        "            label.append(np.array(data[2]))\n",
        "\n",
        "        return (np.array(image_data),np.array(token_data)),np.array(label)\n",
        "\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.datas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af7b23e5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.368355Z",
          "iopub.status.busy": "2025-03-09T17:46:10.368049Z",
          "iopub.status.idle": "2025-03-09T17:46:10.374932Z",
          "shell.execute_reply": "2025-03-09T17:46:10.374076Z"
        },
        "papermill": {
          "duration": 0.021499,
          "end_time": "2025-03-09T17:46:10.376630",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.355131",
          "status": "completed"
        },
        "tags": [],
        "id": "af7b23e5"
      },
      "outputs": [],
      "source": [
        "#checkpoints\n",
        "class CustomCheckpoint(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        try:\n",
        "            with open(f'/kaggle/working/training.log','a') as f:\n",
        "\n",
        "                f.write(f\"{logs['loss']},{logs['masked_accuracy']},{logs['val_loss']},{logs['val_masked_accuracy']}\\n\")\n",
        "\n",
        "        except:\n",
        "\n",
        "\n",
        "            with open(f'/kaggle/working/training.log','w') as f:\n",
        "                    f.write(f\"{logs['loss']},{logs['masked_accuracy']},{logs['val_loss']},{logs['val_masked_accuracy']}\\n\")\n",
        "\n",
        "        self.model.save(f\"model{epoch}.h5\")\n",
        "    def on_batch_end(self,batch,logs=None):\n",
        "        try:\n",
        "            with open(f'/kaggle/working/batch_training.log','a') as f:\n",
        "                f.write(f\"{logs['loss']},{logs['masked_accuracy']}\\n\")\n",
        "\n",
        "        except:\n",
        "\n",
        "\n",
        "            with open(f'/kaggle/working/batch_training.log','w') as f:\n",
        "                    f.write(f\"{logs['loss']},{logs['masked_accuracy']}\\n\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14bcd590",
      "metadata": {
        "papermill": {
          "duration": 0.009846,
          "end_time": "2025-03-09T17:46:10.397829",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.387983",
          "status": "completed"
        },
        "tags": [],
        "id": "14bcd590"
      },
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "078cb55f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.419476Z",
          "iopub.status.busy": "2025-03-09T17:46:10.419247Z",
          "iopub.status.idle": "2025-03-09T17:46:10.425304Z",
          "shell.execute_reply": "2025-03-09T17:46:10.424586Z"
        },
        "papermill": {
          "duration": 0.019216,
          "end_time": "2025-03-09T17:46:10.426883",
          "exception": false,
          "start_time": "2025-03-09T17:46:10.407667",
          "status": "completed"
        },
        "tags": [],
        "id": "078cb55f"
      },
      "outputs": [],
      "source": [
        "def masked_accuracy(label, pred):\n",
        "  \"\"\"\n",
        "  Calculates the masked accuracy between the true labels and predicted labels.\n",
        "\n",
        "  Args:\n",
        "      label: A tensor of shape (batch_size, seq_length) containing the true labels.\n",
        "      pred: A tensor of shape (batch_size, seq_length, target_vocab_size) containing the predicted labels.\n",
        "\n",
        "  Returns:\n",
        "      A scalar tensor representing the masked accuracy value.\n",
        "\n",
        "  \"\"\"\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
        "def masked_loss(label, pred):\n",
        "  \"\"\"\n",
        "  Calculates the masked sparse categorical cross-entropy loss between the true labels and predicted labels.\n",
        "\n",
        "  Args:\n",
        "      label: A tensor of shape (batch_size, seq_length) containing the true labels.\n",
        "      pred: A tensor of shape (batch_size, seq_length, target_vocab_size) containing the predicted labels.\n",
        "\n",
        "  Returns:\n",
        "      A scalar tensor representing the masked loss value.\n",
        "\n",
        "  \"\"\"\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74db8569",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-03-09T17:46:10.469307Z",
          "iopub.status.busy": "2025-03-09T17:46:10.469039Z",
          "iopub.status.idle": "2025-03-09T17:47:57.039754Z",
          "shell.execute_reply": "2025-03-09T17:47:57.038333Z"
        },
        "papermill": {
          "duration": 106.604484,
          "end_time": "2025-03-09T17:47:57.061821",
          "exception": true,
          "start_time": "2025-03-09T17:46:10.457337",
          "status": "failed"
        },
        "tags": [],
        "id": "74db8569"
      },
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "epochs=20\n",
        "input_shape=(848,608,1)\n",
        "L=3\n",
        "num_heads=7\n",
        "MAX_SEQ_LEN=120\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "\n",
        "\n",
        "    model = Model(model=0,image_size=input_shape,input_shape=input_shape,L=L,num_heads=num_heads,vocab_size=len(t2v),max_seq_length=MAX_SEQ_LEN)\n",
        "    model.summary()\n",
        "    model.compile(\n",
        "            optimizer=tf.optimizers.AdamW(learning_rate=0.001,weight_decay=0.0001),\n",
        "            loss=masked_loss,\n",
        "            metrics=[masked_accuracy])\n",
        "    model.fit(\n",
        "        TrainDataGenerator(train_data,batch_size),\n",
        "        validation_data=TrainDataGenerator(test_data,batch_size),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[CustomCheckpoint()],\n",
        "    )\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c157aaf7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-24T17:47:02.983312Z",
          "iopub.status.busy": "2025-01-24T17:47:02.982491Z",
          "iopub.status.idle": "2025-01-24T17:47:02.990646Z",
          "shell.execute_reply": "2025-01-24T17:47:02.989606Z",
          "shell.execute_reply.started": "2025-01-24T17:47:02.983257Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "c157aaf7"
      },
      "outputs": [],
      "source": [
        "#function to predict from trained model\n",
        "def predict(names,model):\n",
        "    images=[]\n",
        "    tokens=[]\n",
        "    batch_size=len(names)\n",
        "    for obj in names:\n",
        "        images.append(load_image(obj.image))\n",
        "        tokens.append(get_tokens(obj.dsl))\n",
        "    st=np.zeros((batch_size,MAX_SEQ_LEN))\n",
        "    ends=np.zeros(batch_size)\n",
        "    loc=0\n",
        "    while ends.sum()!=batch_size:\n",
        "        cur=np.argmax(model.predict((np.array(images),st),verbose=0),axis=2)[:,loc]\n",
        "        for i in range(len(cur)):\n",
        "            if ends[i]==0:\n",
        "                if cur[i]==t2v['<END>']:\n",
        "                    ends[i]=1\n",
        "                elif loc==MAX_SEQ_LEN-2:\n",
        "                    ends[i]=1\n",
        "                    cur[i]=t2v['<END>']\n",
        "\n",
        "                st[i][loc+1]=cur[i]\n",
        "\n",
        "        loc+=1\n",
        "    return [st[i][1:list(st[i]).index(t2v['<END>'])] for i in range(batch_size)],[token[1:-1] for token in tokens]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "817cff15",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-24T17:47:06.180413Z",
          "iopub.status.busy": "2025-01-24T17:47:06.179870Z",
          "iopub.status.idle": "2025-01-24T17:50:14.235099Z",
          "shell.execute_reply": "2025-01-24T17:50:14.234042Z",
          "shell.execute_reply.started": "2025-01-24T17:47:06.180386Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "817cff15"
      },
      "outputs": [],
      "source": [
        "#Loading Test Dataset\n",
        "datas=[sketch.split(\".\")[0] for sketch in  os.listdir(f'/kaggle/input/mymodels/handmade/sketch')]\n",
        "test_data=[Data(f'/kaggle/input/mymodels/handmade/sketch/{i}.jpg',f'/kaggle/input/mymodels/handmade/dsl/{i}.dsl') for i in datas]\n",
        "print([data.image for data in test_data])\n",
        "ref=[]\n",
        "hypo=[]\n",
        "batch_size=32\n",
        "for i in range(0,len(test_data),batch_size):\n",
        "    print(i)\n",
        "    if(i+batch_size)>=len(test_data):\n",
        "           predicted,tokens= predict(test_data[i:],model)\n",
        "    else:\n",
        "        predicted,tokens=predict(test_data[i:i+batch_size],model)\n",
        "    ref+=list(predicted)\n",
        "    hypo+=list(tokens)\n",
        "\n",
        "#Dumping Result\n",
        "with open(\"result.json\",'w') as f:\n",
        "    json.dump({\"ref\":[list(ref[i]) for i in range(len(ref))],\"predicted\":hypo},f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffbd6f9b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-24T17:56:18.522377Z",
          "iopub.status.busy": "2025-01-24T17:56:18.521616Z",
          "iopub.status.idle": "2025-01-24T17:56:18.994507Z",
          "shell.execute_reply": "2025-01-24T17:56:18.993658Z",
          "shell.execute_reply.started": "2025-01-24T17:56:18.522346Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ffbd6f9b"
      },
      "outputs": [],
      "source": [
        "#BLEU Metrics\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "total=[]\n",
        "def calculate_bleu_scores(references, hypotheses, n_gram):\n",
        "    weights = tuple([1.0 / n_gram] * n_gram + [0] * (4 - n_gram))\n",
        "    scores = []\n",
        "\n",
        "    for reference, hypothesis in zip(references, hypotheses):\n",
        "        score = sentence_bleu([reference], hypothesis, weights=weights)\n",
        "        scores.append(score)\n",
        "    total.append(scores)\n",
        "\n",
        "    return np.average(scores)\n",
        "for n in range(1,11):\n",
        "    print(calculate_bleu_scores([list(ref[i]) for i in range(len(ref))],hypo,n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "936f968f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-24T17:56:40.606368Z",
          "iopub.status.busy": "2025-01-24T17:56:40.606043Z",
          "iopub.status.idle": "2025-01-24T17:56:49.748538Z",
          "shell.execute_reply": "2025-01-24T17:56:49.747472Z",
          "shell.execute_reply.started": "2025-01-24T17:56:40.606337Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "936f968f"
      },
      "outputs": [],
      "source": [
        "#Rouge Metric\n",
        "from rouge_score import rouge_scorer\n",
        "sc=['rouge1', 'rouge2','rouge5','rougeL']\n",
        "scorer = rouge_scorer.RougeScorer(sc, use_stemmer=True)\n",
        "rouges={x:{'precision':[],'recall':[],'f1':[]} for x in sc}\n",
        "# Calculate ROUGE scores for each reference-candidate pair\n",
        "for rf, cand in zip([list(ref[i]) for i in range(len(ref))],hypo):\n",
        "    rf=' '.join([v2t[e] for e in rf])\n",
        "    cand=' '.join([v2t[e] for e in cand])\n",
        "    scores = scorer.score(rf, cand)\n",
        "    for key, value in scores.items():\n",
        "        rouges[key]['precision'].append(value.precision)\n",
        "        rouges[key]['recall'].append(value.recall)\n",
        "        rouges[key]['f1'].append(value.fmeasure)\n",
        "\n",
        "for rg in rouges.keys():\n",
        "    print(np.argmax(rouges[rg]['f1']),np.argmin(rouges[rg]['f1']))\n",
        "\n",
        "    for m in ['precision','recall','f1']:\n",
        "\n",
        "        rouges[rg][m]=sorted(rouges[rg][m])\n",
        "\n",
        "        print('scores'+f\"({m}):\",np.average( rouges[rg][m]))\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 5439998,
          "sourceId": 9026287,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5457598,
          "sourceId": 9055515,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5460258,
          "sourceId": 9119854,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6229033,
          "sourceId": 10102008,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6347141,
          "sourceId": 10402953,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6534296,
          "sourceId": 10572152,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 148.154843,
      "end_time": "2025-03-09T17:48:00.660669",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-03-09T17:45:32.505826",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}